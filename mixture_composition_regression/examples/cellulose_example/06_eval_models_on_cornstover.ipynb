{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d808f483-a183-416a-afa3-bc224068205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dabd666f-375d-415a-99f6-532f70471a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_range_files(filenames:list):\n",
    "    ranges = []\n",
    "    \n",
    "    for f in filenames:\n",
    "        with open(f, 'r') as file:\n",
    "            ranges.append(file.readlines())\n",
    "        \n",
    "    ranges = [float(i.strip()) for row in ranges for i in row]\n",
    "    ranges = [[ranges[idx], ranges[idx+1]] for idx, i in enumerate(ranges) if idx % 2 == 0]\n",
    "    \n",
    "    return ranges\n",
    "\n",
    "\n",
    "def read_predictor_files(filenames:list):\n",
    "    \n",
    "    predictors = []\n",
    "    for f in predictor_files:\n",
    "        with open(f, 'rb') as file:\n",
    "            predictors.append(pickle.load(file))\n",
    "    return predictors\n",
    "\n",
    "def predict_on_test_csvs(fpath, bestmodel_container, regressand, target, sample_name=None, print_sample=False, printres=False):\n",
    "    new_data = pd.read_csv(fpath, \n",
    "#                        names=['wavenumber', 'absorbance'], \n",
    "                       header=0, # it was reading in the first row as data and causing problems. So I just had it read the column namese from the first row\n",
    "                       dtype='float')  \n",
    "    \n",
    "    # renamed for less typing, but you can absolutely get rid of these column names and just rename to your preference\n",
    "    new_data = new_data.rename(columns={new_data.columns[0]:'x', new_data.columns[1]:'y'}) \n",
    "\n",
    "    # because if you look higher in the code, we are currently regressing on the derivative of the data\n",
    "    # so I calculated the derivative here\n",
    "    if regressand == 'a':\n",
    "        new_data[regressand] = new_data['y']\n",
    "    if regressand == 'da':\n",
    "        new_data[regressand] = new_data['y'].diff() \n",
    "    elif regressand == 'd2a':\n",
    "        new_data[regressand] = new_data['y'].diff(order=2)\n",
    "\n",
    "\n",
    "    # get the wavelength window we care about and slice the data, only keeping that stuff\n",
    "    window = bestmodel_container[1] \n",
    "    new_data = new_data.where(new_data['x'] > window[0]).where(new_data['x'] < window[1]).dropna()\n",
    "    new_data_dy = np.array(new_data[regressand]).reshape(1,-1)\n",
    "\n",
    "    predictor = bestmodel_container[0]\n",
    "    prediction = predictor.predict(new_data_dy)\n",
    "    \n",
    "    # discard unwanted nested lists\n",
    "    for i in prediction.shape:\n",
    "        prediction = prediction[0] \n",
    "        \n",
    "    if print_sample is True:\n",
    "        print('Sample: {}'.format(sample_name))\n",
    "        \n",
    "    if printres:\n",
    "        print(\"predicted composition {} {:1.3f}\".format(target, prediction))\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def regrid_ir_spectrum(data: pd.DataFrame, xgrid: np.array, drop_original=True):\n",
    "    # assuming the data has only absorption data in a column called 'a' and wavenumbers in a column called 'x'\n",
    "\n",
    "    # do the regridding and add the new x axis as a column\n",
    "    data['a_interp'] = griddata(data['x'], data['a'], xgrid)\n",
    "    data['x_interp'] = xgrid\n",
    "\n",
    "    # store the old data with the tag 'original' and remove th 'interp' tag from the new data \n",
    "    data = data.rename(columns = {'a':'a_original','x':'x_original'})\n",
    "    data = data.rename(columns = {'a_interp': 'a', 'x_interp': 'x'})\n",
    "\n",
    "    # do you want the old data? I don't recommend keeping it for this purpose, but I gave you the option.\n",
    "    if drop_original: \n",
    "        data = data.drop(['a_original', 'x_original'])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d0b5d8-71f7-420e-abce-b52fcbbb834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_files = ['cellulose_predictor.pkl', 'hemi_predictor.pkl', 'lignin_predictor.pkl']\n",
    "predictor_files = ['./trained_models/' + p for p in predictor_files]\n",
    "predictor_metadata_files = [p.split('.pkl')[0] + '_meta.txt' for p in predictor_files] \n",
    "\n",
    "ranges = read_range_files(predictor_metadata_files)\n",
    "predictors = read_predictor_files(predictor_files)\n",
    "containers = [[j,i] for i, j in zip(ranges, predictors)]\n",
    "c_container = containers[0]\n",
    "h_container = containers[1]\n",
    "l_container = containers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fee4d8e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m sample_names \u001b[38;5;241m=\u001b[39m [j\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m temp_paths]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(temp_paths, sample_names):\n\u001b[0;32m----> 4\u001b[0m     temp_paths \u001b[38;5;241m=\u001b[39m regrid_ir_spectrum(temp_paths, x, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "temp_paths = [j for j in os.listdir() if ('-' in j and ('.csv' in j or '.CSV' in j))]\n",
    "sample_names = [j.split('.')[0] for j in temp_paths]\n",
    "for f, n in zip(temp_paths, sample_names):\n",
    "    temp_paths = regrid_ir_spectrum(temp_paths, x, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa626aa-1b31-499e-94ad-9f2caf168cbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fpaths \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir() \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m i \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m i \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.CSV\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m i))]\n\u001b[1;32m      2\u001b[0m c_list, h_list, l_list \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m      3\u001b[0m sample_names \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m fpaths]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "fpaths = [i for i in os.listdir() if ('-' in i and ('.csv' in i or '.CSV' in i))]\n",
    "c_list, h_list, l_list = [], [], []\n",
    "sample_names = [i.split('.')[0] for i in fpaths]\n",
    "regressand = 'da'\n",
    "for f, n in zip(fpaths, sample_names):\n",
    "    l = predict_on_test_csvs(f, l_container, regressand, 'lignin', sample_name=n, printres=True, print_sample=True)\n",
    "    l_list.append(l)\n",
    "    c = predict_on_test_csvs(f, c_container, regressand, 'cellulose',sample_name=n, printres=True)\n",
    "    c_list.append(c)\n",
    "    h = predict_on_test_csvs(f, h_container, regressand, 'hemicellulose',sample_name=n, printres=True)\n",
    "    h_list.append(h)\n",
    "    # h_list.append(1 - c - l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3b4ea-d033-4682-95c8-5bb6060dcf64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ea37c-bdda-4703-8f2b-ac6bcf691e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79874a-f853-4b32-a567-48f6160a3436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be0599-b283-440e-a4f0-c7099f5b0a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b8e31-a4a1-4a15-b8f2-f5355c131374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3b4a8-980b-4539-94ad-36a91f4c67d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
